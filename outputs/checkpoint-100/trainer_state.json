{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6379585326953748,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006379585326953748,
      "grad_norm": 0.453451007604599,
      "learning_rate": 4.000000000000001e-06,
      "loss": 3.2656,
      "step": 1
    },
    {
      "epoch": 0.012759170653907496,
      "grad_norm": 0.3410649597644806,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.0887,
      "step": 2
    },
    {
      "epoch": 0.019138755980861243,
      "grad_norm": 0.276710569858551,
      "learning_rate": 1.2e-05,
      "loss": 2.572,
      "step": 3
    },
    {
      "epoch": 0.025518341307814992,
      "grad_norm": 0.3830925524234772,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.0543,
      "step": 4
    },
    {
      "epoch": 0.03189792663476874,
      "grad_norm": 0.302030473947525,
      "learning_rate": 2e-05,
      "loss": 2.6787,
      "step": 5
    },
    {
      "epoch": 0.03827751196172249,
      "grad_norm": 0.36655664443969727,
      "learning_rate": 2.4e-05,
      "loss": 3.0314,
      "step": 6
    },
    {
      "epoch": 0.044657097288676235,
      "grad_norm": 0.4255586862564087,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.332,
      "step": 7
    },
    {
      "epoch": 0.051036682615629984,
      "grad_norm": 0.40485456585884094,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.1102,
      "step": 8
    },
    {
      "epoch": 0.05741626794258373,
      "grad_norm": 0.3360300660133362,
      "learning_rate": 3.6e-05,
      "loss": 2.9623,
      "step": 9
    },
    {
      "epoch": 0.06379585326953748,
      "grad_norm": 0.5187854170799255,
      "learning_rate": 4e-05,
      "loss": 3.4327,
      "step": 10
    },
    {
      "epoch": 0.07017543859649122,
      "grad_norm": 0.403906911611557,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.7246,
      "step": 11
    },
    {
      "epoch": 0.07655502392344497,
      "grad_norm": 0.3386574387550354,
      "learning_rate": 4.8e-05,
      "loss": 2.8816,
      "step": 12
    },
    {
      "epoch": 0.08293460925039872,
      "grad_norm": 0.3594581186771393,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 2.659,
      "step": 13
    },
    {
      "epoch": 0.08931419457735247,
      "grad_norm": 0.6408626437187195,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 3.2678,
      "step": 14
    },
    {
      "epoch": 0.09569377990430622,
      "grad_norm": 0.7232866287231445,
      "learning_rate": 6e-05,
      "loss": 3.0311,
      "step": 15
    },
    {
      "epoch": 0.10207336523125997,
      "grad_norm": 0.6320794820785522,
      "learning_rate": 6.400000000000001e-05,
      "loss": 3.0533,
      "step": 16
    },
    {
      "epoch": 0.10845295055821372,
      "grad_norm": 0.7244372963905334,
      "learning_rate": 6.800000000000001e-05,
      "loss": 2.9034,
      "step": 17
    },
    {
      "epoch": 0.11483253588516747,
      "grad_norm": 0.6189438700675964,
      "learning_rate": 7.2e-05,
      "loss": 2.3078,
      "step": 18
    },
    {
      "epoch": 0.12121212121212122,
      "grad_norm": 0.8212248086929321,
      "learning_rate": 7.6e-05,
      "loss": 2.7358,
      "step": 19
    },
    {
      "epoch": 0.12759170653907495,
      "grad_norm": 0.7248872518539429,
      "learning_rate": 8e-05,
      "loss": 2.6795,
      "step": 20
    },
    {
      "epoch": 0.1339712918660287,
      "grad_norm": 0.9034414887428284,
      "learning_rate": 8.4e-05,
      "loss": 2.893,
      "step": 21
    },
    {
      "epoch": 0.14035087719298245,
      "grad_norm": 0.616949737071991,
      "learning_rate": 8.800000000000001e-05,
      "loss": 2.76,
      "step": 22
    },
    {
      "epoch": 0.1467304625199362,
      "grad_norm": 0.7575112581253052,
      "learning_rate": 9.200000000000001e-05,
      "loss": 3.0376,
      "step": 23
    },
    {
      "epoch": 0.15311004784688995,
      "grad_norm": 1.0330862998962402,
      "learning_rate": 9.6e-05,
      "loss": 2.8336,
      "step": 24
    },
    {
      "epoch": 0.1594896331738437,
      "grad_norm": 1.3751707077026367,
      "learning_rate": 0.0001,
      "loss": 2.7561,
      "step": 25
    },
    {
      "epoch": 0.16586921850079744,
      "grad_norm": 1.175480842590332,
      "learning_rate": 0.00010400000000000001,
      "loss": 2.8454,
      "step": 26
    },
    {
      "epoch": 0.1722488038277512,
      "grad_norm": 0.9479580521583557,
      "learning_rate": 0.00010800000000000001,
      "loss": 2.4816,
      "step": 27
    },
    {
      "epoch": 0.17862838915470494,
      "grad_norm": 1.2111488580703735,
      "learning_rate": 0.00011200000000000001,
      "loss": 2.1506,
      "step": 28
    },
    {
      "epoch": 0.1850079744816587,
      "grad_norm": 1.530025839805603,
      "learning_rate": 0.000116,
      "loss": 2.4322,
      "step": 29
    },
    {
      "epoch": 0.19138755980861244,
      "grad_norm": 1.1384165287017822,
      "learning_rate": 0.00012,
      "loss": 2.4709,
      "step": 30
    },
    {
      "epoch": 0.19776714513556617,
      "grad_norm": 1.0709502696990967,
      "learning_rate": 0.000124,
      "loss": 2.4375,
      "step": 31
    },
    {
      "epoch": 0.20414673046251994,
      "grad_norm": 1.4657416343688965,
      "learning_rate": 0.00012800000000000002,
      "loss": 2.0052,
      "step": 32
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 0.8392416834831238,
      "learning_rate": 0.000132,
      "loss": 2.1016,
      "step": 33
    },
    {
      "epoch": 0.21690590111642744,
      "grad_norm": 1.2753723859786987,
      "learning_rate": 0.00013600000000000003,
      "loss": 2.4355,
      "step": 34
    },
    {
      "epoch": 0.22328548644338117,
      "grad_norm": 0.8943312764167786,
      "learning_rate": 0.00014,
      "loss": 1.6851,
      "step": 35
    },
    {
      "epoch": 0.22966507177033493,
      "grad_norm": 0.9601629376411438,
      "learning_rate": 0.000144,
      "loss": 2.0078,
      "step": 36
    },
    {
      "epoch": 0.23604465709728867,
      "grad_norm": 2.0272886753082275,
      "learning_rate": 0.000148,
      "loss": 2.0393,
      "step": 37
    },
    {
      "epoch": 0.24242424242424243,
      "grad_norm": 1.1839101314544678,
      "learning_rate": 0.000152,
      "loss": 2.1301,
      "step": 38
    },
    {
      "epoch": 0.24880382775119617,
      "grad_norm": 0.7975348830223083,
      "learning_rate": 0.00015600000000000002,
      "loss": 2.1206,
      "step": 39
    },
    {
      "epoch": 0.2551834130781499,
      "grad_norm": 0.763093888759613,
      "learning_rate": 0.00016,
      "loss": 2.3389,
      "step": 40
    },
    {
      "epoch": 0.26156299840510366,
      "grad_norm": 1.1932562589645386,
      "learning_rate": 0.000164,
      "loss": 2.0811,
      "step": 41
    },
    {
      "epoch": 0.2679425837320574,
      "grad_norm": 0.782232403755188,
      "learning_rate": 0.000168,
      "loss": 2.1586,
      "step": 42
    },
    {
      "epoch": 0.2743221690590112,
      "grad_norm": 1.4949003458023071,
      "learning_rate": 0.000172,
      "loss": 1.7675,
      "step": 43
    },
    {
      "epoch": 0.2807017543859649,
      "grad_norm": 1.0152385234832764,
      "learning_rate": 0.00017600000000000002,
      "loss": 1.7395,
      "step": 44
    },
    {
      "epoch": 0.28708133971291866,
      "grad_norm": 0.7600171566009521,
      "learning_rate": 0.00018,
      "loss": 1.6513,
      "step": 45
    },
    {
      "epoch": 0.2934609250398724,
      "grad_norm": 0.9400573372840881,
      "learning_rate": 0.00018400000000000003,
      "loss": 2.0416,
      "step": 46
    },
    {
      "epoch": 0.29984051036682613,
      "grad_norm": 0.8367407917976379,
      "learning_rate": 0.000188,
      "loss": 1.566,
      "step": 47
    },
    {
      "epoch": 0.3062200956937799,
      "grad_norm": 1.189307689666748,
      "learning_rate": 0.000192,
      "loss": 1.7726,
      "step": 48
    },
    {
      "epoch": 0.31259968102073366,
      "grad_norm": 0.9933138489723206,
      "learning_rate": 0.000196,
      "loss": 1.8142,
      "step": 49
    },
    {
      "epoch": 0.3189792663476874,
      "grad_norm": 1.1799002885818481,
      "learning_rate": 0.0002,
      "loss": 1.668,
      "step": 50
    },
    {
      "epoch": 0.3253588516746411,
      "grad_norm": 1.5572706460952759,
      "learning_rate": 0.000196,
      "loss": 2.0057,
      "step": 51
    },
    {
      "epoch": 0.3317384370015949,
      "grad_norm": 0.7851872444152832,
      "learning_rate": 0.000192,
      "loss": 1.9061,
      "step": 52
    },
    {
      "epoch": 0.33811802232854865,
      "grad_norm": 1.0199326276779175,
      "learning_rate": 0.000188,
      "loss": 1.4843,
      "step": 53
    },
    {
      "epoch": 0.3444976076555024,
      "grad_norm": 0.8278627395629883,
      "learning_rate": 0.00018400000000000003,
      "loss": 1.5273,
      "step": 54
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.5848453640937805,
      "learning_rate": 0.00018,
      "loss": 1.5513,
      "step": 55
    },
    {
      "epoch": 0.3572567783094099,
      "grad_norm": 0.5398955941200256,
      "learning_rate": 0.00017600000000000002,
      "loss": 1.8652,
      "step": 56
    },
    {
      "epoch": 0.36363636363636365,
      "grad_norm": 0.5973206162452698,
      "learning_rate": 0.000172,
      "loss": 1.9702,
      "step": 57
    },
    {
      "epoch": 0.3700159489633174,
      "grad_norm": 0.6370507478713989,
      "learning_rate": 0.000168,
      "loss": 1.6218,
      "step": 58
    },
    {
      "epoch": 0.3763955342902711,
      "grad_norm": 0.6120108366012573,
      "learning_rate": 0.000164,
      "loss": 1.6505,
      "step": 59
    },
    {
      "epoch": 0.3827751196172249,
      "grad_norm": 0.7082598209381104,
      "learning_rate": 0.00016,
      "loss": 1.7258,
      "step": 60
    },
    {
      "epoch": 0.38915470494417864,
      "grad_norm": 1.0763036012649536,
      "learning_rate": 0.00015600000000000002,
      "loss": 2.0096,
      "step": 61
    },
    {
      "epoch": 0.39553429027113235,
      "grad_norm": 0.6007619500160217,
      "learning_rate": 0.000152,
      "loss": 1.5846,
      "step": 62
    },
    {
      "epoch": 0.4019138755980861,
      "grad_norm": 0.5850499868392944,
      "learning_rate": 0.000148,
      "loss": 1.7832,
      "step": 63
    },
    {
      "epoch": 0.4082934609250399,
      "grad_norm": 0.61747145652771,
      "learning_rate": 0.000144,
      "loss": 1.6683,
      "step": 64
    },
    {
      "epoch": 0.41467304625199364,
      "grad_norm": 0.739189624786377,
      "learning_rate": 0.00014,
      "loss": 1.3964,
      "step": 65
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 0.4258177578449249,
      "learning_rate": 0.00013600000000000003,
      "loss": 1.7163,
      "step": 66
    },
    {
      "epoch": 0.4274322169059011,
      "grad_norm": 0.6101560592651367,
      "learning_rate": 0.000132,
      "loss": 1.7748,
      "step": 67
    },
    {
      "epoch": 0.43381180223285487,
      "grad_norm": 0.8824165463447571,
      "learning_rate": 0.00012800000000000002,
      "loss": 1.8785,
      "step": 68
    },
    {
      "epoch": 0.44019138755980863,
      "grad_norm": 0.7749235033988953,
      "learning_rate": 0.000124,
      "loss": 1.7923,
      "step": 69
    },
    {
      "epoch": 0.44657097288676234,
      "grad_norm": 0.48854508996009827,
      "learning_rate": 0.00012,
      "loss": 2.203,
      "step": 70
    },
    {
      "epoch": 0.4529505582137161,
      "grad_norm": 0.4423340857028961,
      "learning_rate": 0.000116,
      "loss": 1.8022,
      "step": 71
    },
    {
      "epoch": 0.45933014354066987,
      "grad_norm": 0.6152393221855164,
      "learning_rate": 0.00011200000000000001,
      "loss": 1.9581,
      "step": 72
    },
    {
      "epoch": 0.46570972886762363,
      "grad_norm": 0.6683456897735596,
      "learning_rate": 0.00010800000000000001,
      "loss": 1.753,
      "step": 73
    },
    {
      "epoch": 0.47208931419457734,
      "grad_norm": 0.9283868074417114,
      "learning_rate": 0.00010400000000000001,
      "loss": 1.8586,
      "step": 74
    },
    {
      "epoch": 0.4784688995215311,
      "grad_norm": 0.46362829208374023,
      "learning_rate": 0.0001,
      "loss": 1.6457,
      "step": 75
    },
    {
      "epoch": 0.48484848484848486,
      "grad_norm": 0.4998917281627655,
      "learning_rate": 9.6e-05,
      "loss": 1.6265,
      "step": 76
    },
    {
      "epoch": 0.49122807017543857,
      "grad_norm": 0.6301130056381226,
      "learning_rate": 9.200000000000001e-05,
      "loss": 1.4,
      "step": 77
    },
    {
      "epoch": 0.49760765550239233,
      "grad_norm": 0.5538380742073059,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.6045,
      "step": 78
    },
    {
      "epoch": 0.5039872408293461,
      "grad_norm": 0.4043886363506317,
      "learning_rate": 8.4e-05,
      "loss": 1.7657,
      "step": 79
    },
    {
      "epoch": 0.5103668261562998,
      "grad_norm": 0.5227323174476624,
      "learning_rate": 8e-05,
      "loss": 1.7726,
      "step": 80
    },
    {
      "epoch": 0.5167464114832536,
      "grad_norm": 0.6547805666923523,
      "learning_rate": 7.6e-05,
      "loss": 1.5745,
      "step": 81
    },
    {
      "epoch": 0.5231259968102073,
      "grad_norm": 0.570052444934845,
      "learning_rate": 7.2e-05,
      "loss": 1.6431,
      "step": 82
    },
    {
      "epoch": 0.529505582137161,
      "grad_norm": 0.5697196125984192,
      "learning_rate": 6.800000000000001e-05,
      "loss": 1.5814,
      "step": 83
    },
    {
      "epoch": 0.5358851674641149,
      "grad_norm": 0.4436632990837097,
      "learning_rate": 6.400000000000001e-05,
      "loss": 1.585,
      "step": 84
    },
    {
      "epoch": 0.5422647527910686,
      "grad_norm": 0.5445744395256042,
      "learning_rate": 6e-05,
      "loss": 1.9837,
      "step": 85
    },
    {
      "epoch": 0.5486443381180224,
      "grad_norm": 0.780221164226532,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 1.8976,
      "step": 86
    },
    {
      "epoch": 0.5550239234449761,
      "grad_norm": 0.6360467076301575,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 1.822,
      "step": 87
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 0.4964759647846222,
      "learning_rate": 4.8e-05,
      "loss": 1.7774,
      "step": 88
    },
    {
      "epoch": 0.5677830940988836,
      "grad_norm": 0.5720850229263306,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.7507,
      "step": 89
    },
    {
      "epoch": 0.5741626794258373,
      "grad_norm": 0.8324241042137146,
      "learning_rate": 4e-05,
      "loss": 1.2528,
      "step": 90
    },
    {
      "epoch": 0.580542264752791,
      "grad_norm": 0.4945969581604004,
      "learning_rate": 3.6e-05,
      "loss": 1.7749,
      "step": 91
    },
    {
      "epoch": 0.5869218500797448,
      "grad_norm": 0.5513239502906799,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.9163,
      "step": 92
    },
    {
      "epoch": 0.5933014354066986,
      "grad_norm": 0.4657042920589447,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.5722,
      "step": 93
    },
    {
      "epoch": 0.5996810207336523,
      "grad_norm": 0.42612701654434204,
      "learning_rate": 2.4e-05,
      "loss": 1.8465,
      "step": 94
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 0.7391176819801331,
      "learning_rate": 2e-05,
      "loss": 2.0639,
      "step": 95
    },
    {
      "epoch": 0.6124401913875598,
      "grad_norm": 0.5083274841308594,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.006,
      "step": 96
    },
    {
      "epoch": 0.6188197767145136,
      "grad_norm": 0.7552103996276855,
      "learning_rate": 1.2e-05,
      "loss": 1.686,
      "step": 97
    },
    {
      "epoch": 0.6251993620414673,
      "grad_norm": 0.9554054141044617,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.827,
      "step": 98
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.620807409286499,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.5294,
      "step": 99
    },
    {
      "epoch": 0.6379585326953748,
      "grad_norm": 0.479306161403656,
      "learning_rate": 0.0,
      "loss": 1.6322,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4225865951969280.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
